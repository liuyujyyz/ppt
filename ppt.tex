\documentclass{beamer}
\setbeamertemplate{caption}[numbered]{}
\usepackage{multicol}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{setspace}
\newcommand{\per}{\mathrm{Per}}
\newcommand{\eat}[1]{}
\newcommand{\topic}[1]{\noindent{{\bf #1}:}}
\newcommand{\calX}{{\mathcal X}}
\newcommand{\calH}{{\mathcal H}}
\newcommand{\calC}{{\mathcal C}}
\newcommand{\calD}{{\mathcal D}}
\newcommand{\calL}{{\mathcal L}}
\newcommand{\calF}{{\mathcal F}}
\newcommand{\calP}{{\mathcal P}}
\newcommand{\calS}{{\mathcal S}}
\newcommand{\calT}{{\mathcal T}}
\newcommand{\calM}{{\mathcal M}}
\newcommand{\calN}{{\mathcal N}}
\newcommand{\calR}{{\mathcal R}}
\newcommand{\tuple}[1]{\left(#1\right)}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\defeq}{\triangleq}

\newcommand{\Prob}{{\operatorname{Pr}}}
\newcommand{\Exp}{{\mathbb{E}}}
\newcommand{\E}{{\mathbb{E}}}
\newcommand{\G}{{\mathcal{G}}}
\newcommand{\R}{{\mathbf{R}}}
\renewcommand{\H}{{\mathcal{H}}}
\newcommand{\T}{{\mathcal{T}}}
\renewcommand{\P}{{\mathcal P}}
\renewcommand{\r}{{\mathbf{r}}}

\newcommand{\hpf}{\Psi(\calP)}

\newcommand{\Var}{\operatorname{Var}}
\newcommand{\dist}{\mathrm{d}}
\renewcommand{\d}{\mathrm{d}}

\newcommand{\depth}{\mathsf{depth}}
\newcommand{\rank}{\mathsf{rank}}
\newcommand{\opt}{\mathsf{OPT}}
\newcommand{\sol}{\mathsf{SOL}}
\newcommand{\vol}{\mathsf{vol}}
\newcommand{\cost}{\mathsf{cost}}
\newcommand{\FA}{\mathrm{FPRAS}}
\newcommand{\sharpP}{\#\mathrm{P}}
\newcommand{\inapp}{\mathrm{Inapprox}}
\newcommand{\open}{\mathrm{Open}}

\newcommand{\B}{\mathsf{B}}

\newcommand{\tB}{\widetilde{B}}
\newcommand{\A}[1]{\langle #1\rangle}
\newcommand{\e}{\epsilon}
\newcommand{\bS}{\bar{S}}

\newcommand{\true}{\mathsf{true}}
\newcommand{\false}{\mathsf{false}}

\newcommand{\hx}{\widehat{x}}
\newcommand{\hy}{\widehat{y}}
\newcommand{\hz}{\widehat{z}}
\newcommand{\tx}{\widetilde{x}}
\newcommand{\ty}{\widetilde{y}}
\newcommand{\tz}{\widetilde{z}}
\newcommand{\hg}{\widehat{g}}
\newcommand{\bg}{\bar{g}}
\newcommand{\bd}{\bar{d}}
\newcommand{\td}{\tilde{d}}
\newcommand{\V}{\mathcal{V}}
\renewcommand{\L}{\mathsf{T}}
\newcommand{\U}{\mathcal{U}}

\newcommand{\iin}{\mathsf{In}}
\newcommand{\poly}{\mathrm{poly}}

%\newcommand{\diam}{\mathsf{D}}
%\newcommand{\C}{\mathsf{C}}
%\newcommand{\DCP}{\mathsf{DCP}}
%\newcommand{\CP}{\mathsf{CP}}
%\newcommand{\MST}{\mathsf{MST}}
%\newcommand{\M}{\mathsf{M}}
%\newcommand{\MM}{\mathsf{MPM}}
%\newcommand{\CC}{\mathsf{CC}}
%\newcommand{\CH}{\mathsf{CH}}
%\newcommand{\DT}{\mathsf{DT}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\D}{\mathsf{D}}
\newcommand{\C}{\mathsf{C}}
\newcommand{\DCP}{\mathsf{C}}
\newcommand{\KCP}{\mathsf{kC}}
\newcommand{\CP}{\mathsf{CP}}
\newcommand{\KC}{\mathsf{kCL}}
\newcommand{\MST}{\mathsf{MST}}
\newcommand{\CH}{\mathsf{C}}
\newcommand{\DT}{\mathsf{C}}
\newcommand{\NN}{\mathsf{NN}}
\newcommand{\KMNN}{\mathsf{kmNN}}

\newcommand{\core}{stoch-core}
\newcommand{\MM}{{\textsf{MAXIMUM-ELEMENT}}}
\newcommand{\mm}{{\textsf{MINIMUM-ELEMENT}}}
\newcommand{\MS}{{\textsf{MAX-SUM}}}
\newcommand{\ms}{{\textsf{MIN-SUM}}}
\newcommand{\ES}{{\textsf{EXACT-SUM}}}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\p}{p}
\newcommand{\Cl}{\mathsf{Cl}}
\newcommand{\Home}{\mathcal{H}}

\newcommand{\etal}{et al. }
\newcommand{\realize}{\vDash}
\newcommand{\consistent}{\thicksim}
\newcommand{\red}[1]{\textcolor{red}{#1}}

\newcommand{\handr}{\textcolor{magenta}{\HandRight}}
\newcommand{\zhuyi}{\noindent\alert{\handr}}
\newtheorem{conjecture}{Conjecture}
\newcommand{\rmnum}[1]{\romannumeral #1}
\newcommand{\Rmnum}[1]{\expandafter\@slowromancap\romannumeral #1@}

\mode<presentation> {
\usetheme{Madrid}
}
\eat{
v\title[Short title]{Stochastic Extreme Value Optimization} 
\author{Liu Yu} 
\institute[IIIS] 
{
Tsinghua University \\ 
\medskip
\textit{liuyujyyz@gmail.com} 
}
\date{\today} 
}
\newif\iflattersubsect
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\AtBeginSection[]
{
    \frametitle{}\small
   \begin{frame}
    \frametitle{Overview} %
    \tableofcontents[currentsection]
    \end{frame}
    \lattersubsectfalse
}

\AtBeginSubsection[] {
    \iflattersubsect
    \begin{frame}
    \frametitle{Overview} %
    \tableofcontents[currentsubsection]
    \end{frame}
    \fi
    \lattersubsecttrue
}

\title[Thesis Defence]{Stochastic Extreme Value Optimization}
\author[]{Yu Liu\\Advisor: Jian Li\\[0.5em]Email:~\href{liuyujyyz@gmail.com}{\color{blue!70}\texttt{liuyujyyz@gmail.com}}}
\institute[Tsinghua Unversity]{\textcolor{olive}{Institute of Interdisciplinary Information Sciences \\
Tsinghua University
}}
\date{}
\titlegraphic{\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \ \ \includegraphics[scale = 0.1]{tsinghua.eps}}

\begin{frame}
\titlepage
\end{frame}


\begin{frame}
\frametitle{Overview} 
\tableofcontents 
\end{frame}

\section{Introduction}

\begin{frame}
\frametitle{Interview Scheduling}
\begin{spacing}{2.0}

\end{spacing}
\begin{multicols}{2}
    \centering
    \includegraphics[width=0.3\textwidth]{head.eps}%
    \begin{figure}
    \includegraphics[width=0.3\textwidth]{all.eps}
    \begin{spacing}{4.0}

    \end{spacing}
    \onslide<2->{\includegraphics[width=0.3\textwidth]{left.eps}}
\end{figure}
\end{multicols}

Bob has limited time, and only attends interviews of some chosen companies.

\onslide<3->{Which companies should Bob choose to maximize his expected salary?}
%\end{spacing}
\end{frame}

\begin{frame}
\frametitle{Bandit Play}

There are 3 bandits:\\
\begin{center}
\begin{tabular}{|ll|ll|ll|}
\hline
Bandit 1& & Bandit 2& &Bandit 3& \\
\hline
 $0$& $0$ &  $0$& $\frac{1}{2}$ & $0$& $\frac{2}{3}$\\
\hline
 $1$& $1$ &  $2$& $\frac{1}{2}$  & $3$& $\frac{1}{3}$\\
\hline
\end{tabular}
\end{center}

\only<2-2>{
You are charged by 1 to play one bandit and take the reward.
}
\only<3->{
You are charged by 1.5. You can play two of them but take one reward.
\begin{spacing}{2.0}
\begin{center}
\begin{tabular}{c c}
    \onslide<4->{
        Bandit 2, 3: & {\color{red}$\frac{5}{3}$}\\
        Bandit 1, 3: & {\color{red}$\frac{5}{3}$}\\
        Bandit 1, 2: & $\frac{3}{2}$\\
    }
\end{tabular}
\end{center}
\end{spacing}
}
\end{frame}

\begin{frame}
\frametitle{Problem Definition}
    \begin{itemize}
    \item Input 1: a set of choices (companies, bandits);
	\item Input 2: a collection of feasible choice sets (time cost, number of plays);
	\item choose a feasible set to try, take the best.
	\end{itemize}
    \onslide<2->{
\begin{problem}[$\MM$]
Input:
\begin{itemize}
\item a set of independent non-negative random variables $\{X_i\}$;
\item a collection of feasible set $\calF \subset 2^{[n]}$ (Constraint);
\end{itemize}
Output:
\begin{itemize}
\item a set $S\in \calF$, which maximizes $\Exp[\max_{i\in S} X_i]$.
\end{itemize}
\end{problem}
}
\onslide<3->{
Minimization variant: minimize $\Exp[\max_{i\in S} X_i]$.

\mm: $\calF = \{S \mid \sum_{i\in S} c_i \leq C\}$, and minimize $\Exp[\min_{i\in S} X_i]$.}
\end{frame}

\begin{frame}
\frametitle{Examples of Constraints}
A constraint $\calF$ can have exponential size. Assume it can be represented implictly.
\begin{itemize}
\item Cardinality Constraint: $\{S \mid |S| = K\}$;
\item Cost Constraint: $\{S \mid \sum_{i\in S} c_i \leq C\}$;
\item Path Constraint: paths from $s$ to $t$;
\item Cut Constraint: edges between set $V$ and $\bar V$;
\item Matroid Constraint: $([n], \calF)$ consists a Matoid;
\item ...
\end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Adaptivity}
    \begin{itemize}
        \item Adaptive Algorithm: play a bandit and observe the reward, decide which to play next according to previous rewards.
            \begin{spacing}{2.0}

            \end{spacing}
        \item \only<1-1>{Non-adaptive Algorithm}\only<2->{{\color{red}Non-adaptive Algorithm}}: decide chosen companies and take interviews one by one.
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Related Work}
\begin{itemize}
    \item \MM\ is NP-hard.
    \item Goel \etal~\cite{Goel:asking}: a $\frac{1}{4}(1 - \frac{1}{e})$-approximation algorithm for \MM\ under Cost Constraint.
    \item Guha \etal~\cite{Guha07informationacquisition}: the Lagrangian version of \MM\ with Cost Constraint can be solved optimally.
    \item Chen \etal~\cite{NIPS2016:MAB}: online problem and a {\color{red}$(1-\frac{1}{e})$}-approximation offline algorithm for \MM\ under Cardinality Constraint.
    \item Goel \etal studied \mm\ deeply and obtained some important results:\cite{Goel:probe}
    \begin{itemize}
        \item It is NP-hard to approximate with any polynomial ratio under the Cost Constraint;
        \item $ -\log \Exp[\min_{i\in S} X_i]$ is sub-modular;
        \item CIP (Covering Integer Program) approach to design bi-criteria $(1+\varepsilon)$-approximation algorithm with extra cost.
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Notations}
    \begin{itemize}
        \item A discrete random variable $X_i$ takes value over the support set$\{a_{i,1}, \ldots, a_{i, s_i}\}$, with probability $\Pr[X_i = a_{i,j}] = p_{i,j}$. In problems, it is inputted using $\{a_{i,j}\}$ and $\{p_{i,j}\}$.
        \item A Bernoulli random variable has support set $\{0, a > 0\}$.
    \end{itemize}
\end{frame}

\section{MAXIMUM-ELEMENT}

\subsection{Contributions}

\begin{frame}
    \frametitle{Problem Definition}
    \begin{problem}[\MM]
        \begin{itemize}
            \item Input:\\
                a set of independent non-negative random variables $\{X_i\}$,\\
                a constraint $\calF \subset 2^{[n]}$;
            \item Output:\\ a set $S\in \calF$ which maximizes $\Exp[\max_{i\in S} X_i]$.
        \end{itemize}
    \end{problem}
\end{frame}

\begin{frame}
\frametitle{Our Contributions}
\begin{itemize}
    \item In previous work, approximation algorithms based on $M(S) = \Exp[\max_{i\in S} X_i]$ is submodular; 
    \item In our work, 
        \begin{itemize}
            \item the truncation trick introduced, used in similar problems~\cite{kleinberg2000allocating,guha2009exceeding}. 
            \item Constant algorithm under more kinds of constraints.
            \item First PTAS for \MM\ using the discretization and enumeration technique.
        \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}
    \frametitle{Related Problems}
    \begin{problem}[MAX-SUM]
        Input: a set of numbers $\{v_i\}$ and a constraint $\calF$;\\
        Output: a set $S\in \calF$ maximizing $\sum_{i\in S} v_i$.
    \end{problem}
    \begin{problem}[MIN-SUM]
        Input: a set of numbers $\{v_i\}$ and a constraint $\calF$;\\
        Output: a set $S\in\calF$ minimizing $\sum_{i\in S} v_i$.
    \end{problem}
    \begin{problem}[EXACT-SUM]
        Input: a set of integers $\{v_i\}$, a target $T$ and a constraint $\calF$;\\
        Output: a set $S\in \calF$ with $\sum_{i\in S} v_i = T$.
    \end{problem}
\end{frame}

\begin{frame}
\frametitle{Results}
\begin{theorem}[Main Theorem]
    \begin{enumerate}
        \item  A constant approximation algorithm for \MS\\
            $\Rightarrow$ a constant approximation algorithm for \MM;
        \item  A constant approximation algorithm for \ms\\
            $\Rightarrow$ a constant approximation algorithm for minimization variant of \MM;
        \item  A psuedo-polynomial time algorithm for \ES\\
            $\Rightarrow$ PTAS for both \MM\ and minimization variant of \MM.
    \end{enumerate}
\end{theorem}
\end{frame}
\subsection{Constant Approximation}
\begin{frame}
    \frametitle{Constant Approximation}

    \begin{lemma}
        For any set $S$ and constant $T$, if $\Exp[\sum_{i\in S} \max(X_i - T, 0)] \geq T$, we have
        $$\Exp[\max_{i\in S} X_i] \geq T.$$
    \end{lemma}
    \onslide<2->{
    Find a $T$ such that:
    \begin{itemize}
        \item For all set $S\in \calF$, $\sum_{i\in S} \Exp[\max(X_i - T, 0)] \leq T$ (provide a upper bound for optimal solution);
        \item Exist a set $\sol$, $\sum_{i\in \sol} \Exp[\max(X_i - T, 0)] \geq T$ (provide a lower bound for algorithm output).
    \end{itemize}
}
\end{frame}

\subsection{PTAS}
\begin{frame}
    \frametitle{Bernoulli Decomposition}
    \begin{definition}[Bernoulli Decomposition]
        Given a discrete random variable $X$, its Bernoulli decomposition is a set of Bernoulli random variables $\{Z_j\}$ such that $X\sim \max_j Z_j$.
    \end{definition}
    \begin{spacing}{3.0}

    \end{spacing}
    \onslide<2->{
    If $\Pr[X = a_j] = p_j$, for $j = 1, \ldots, N$, 
    $$Z_j = \left\{
        \begin{array}{ll}
            a_j & \text{with probability} \frac{\Pr[X = a_j]}{\Pr[X \leq a_j]},\\
            0 & \text{otherwise}.
        \end{array}
        \right.
        $$
    }
\end{frame}

\begin{frame}
    \frametitle{PTAS: Discretization}
    \begin{itemize}
        \item    Run a constant approximation algorithm to obtain an approximation solution $S$ with objective value $W = \Exp[\max_{i\in S} X_i]$.\\
        \item    Discretize input distributions using their Bernoulli decomposition and the value $W$.\\
        \item    After discretization:
    \begin{itemize}
        \item A set $\mathsf{Supp}$ of size $z = O(\frac{1}{\varepsilon^2})$;
        \item $n$ random variables $\bar X_1, \ldots, \bar X_n$ taking values over set $\mathsf{Supp}$.
        \item The optimal solution for $\{\bar X_i\}$ is close to the one for $\{X_i\}$.
    \end{itemize}
    \end{itemize}

\end{frame}
\begin{frame}
    \frametitle{Discretization}
    \begin{figure}
    \begin{tikzpicture}[
    declare function={binomcoeff(\n,\k)=\n!/(\k!*(\n-\k)!);},
    declare function={
        hypergeompmf(\N,\K,\n,\k)=binomcoeff(\K,\k)*binomcoeff(\N-\K, \n-\k)/binomcoeff(\N,\n);}
    ]
    \begin{axis}[
        samples at={0,2,...,98,100},
        %ycomb,
        yticklabel style={
            /pgf/number format/fixed,
   %         /pgf/number format/fixed zerofill,
     %       /pgf/number format/precision=1
        },
%        every axis legend/.append style={at={(0.2,0.6)}, anchor=south}
    ]
    \addplot [mark=*, cyan] {hypergeompmf(80,25,20,x)};
    \end{axis}
    \end{tikzpicture}
    \caption{A distribution with many supports and long tail.}
\end{figure}
\end{frame}

\begin{frame}
    \frametitle{Discretization}
    \begin{multicols}{2}
    \only<1,3>{
    \begin{figure}
    \begin{tikzpicture}[
            scale = 0.6,
    declare function={binomcoeff(\n,\k)=\n!/(\k!*(\n-\k)!);},
    declare function={
        hypergeompmf(\N,\K,\n,\k)=binomcoeff(\K,\k)*binomcoeff(\N-\K, \n-\k)/binomcoeff(\N,\n);}
    ]
    \begin{axis}[
        samples at={0,1,...,23,24},
        xtick={0,5,10,15,20,25},
        xticklabels={$0$, $5$, $10$, $15$, $20$, $W/\varepsilon$},
        yticklabel style={
             /pgf/number format/fixed,
       %     /pgf/number format/fixed zerofill,
        %    /pgf/number format/precision=1
         },
%        every axis legend/.append style={at={(0.2,0.6)}, anchor=south}
    ]
    \addplot [mark=*, cyan] {hypergeompmf(80,25,20,x)};
    \addplot [mark=*, red] coordinates {(25, {0.01})};
    \end{axis}
    \end{tikzpicture}
    \caption{Cut the tail, part larger than $\frac{W}{\varepsilon}$. }
    \end{figure}}
    \only<2>{
        Round $\bar Z_i$ to a multiple of $u = \varepsilon W$:
        $$\bar Z_i \leftarrow \lfloor \frac{\bar Z_i}{u}\rfloor u,$$
        $$\bar X = \max \bar Z_i.$$
    }%
    \only<1>{
        Bernoulli Decomposition: $Z_1, Z_2, \ldots$;\\
        $Z_i = B(a_i, p_i)$.
        \begin{spacing}{2.0}

        \end{spacing}
        If $a_i \leq \frac{W}{\varepsilon}$, $\bar Z_i = Z_i$;\\
        If $a_i > \frac{W}{\varepsilon}$, $\bar Z_i = B(\frac{W}{\varepsilon}, \Exp[Z_i]\varepsilon/W)$.
        
    }
    \only<2->{
    \begin{figure}
    \begin{tikzpicture}[
            scale = 0.6,
    declare function={binomcoeff(\n,\k)=\n!/(\k!*(\n-\k)!);},
    declare function={
        hypergeommf(\N,\K,\n,\k)=binomcoeff(\K,\k)*binomcoeff(\N-\K, \n-\k)/binomcoeff(\N,\n);},
    declare function={
        hyperadd(\N,\K,\n,\k)=hypergeommf(\N,\K,\n,\k)+hypergeommf(\N,\K,\n,\k+1)+hypergeommf(\N,\K,\n,\k+2);}
    ]
    \begin{axis}[
        samples at={0,3,...,21,24},
        %ycomb,
        xtick={0,3,6,9,15,25},
        xticklabels={$0$, $u$, $2u$, $3u$, $\ldots\ldots$, $W/\varepsilon$}
        %yticklabel style={
        %    /pgf/number format/fixed,
            %/pgf/number format/fixed zerofill,
            %/pgf/number format/precision=1
        %},
%        every axis legend/.append style={at={(0.2,0.6)}, anchor=south}
    ]
    \addplot [mark=*, cyan] {hyperadd(80,25,20,x)};
    \addplot [mark=*, red] coordinates {(25, {0.01})};
    \end{axis}
    \end{tikzpicture}
    \caption{Discretize supports with small steps $u=\varepsilon W$.}
    \end{figure}}
\end{multicols}
\end{frame}

\begin{frame}
    \frametitle{PTAS: Signatures}
    \begin{itemize}
        \item $\bar X_i$ can be Bernoulli decomposed to $\{Y_{i,j}\}_{j=1}^z$.
        \item Signature for $\bar X_i$ ($q_{i,j} = \Pr[Y_{i,j} = 0]$):
            $$\mathsf{Sig}(\bar X_i) = (\lfloor \frac{-\log(q_{i,1})}{\varepsilon^4 / n}\rfloor\varepsilon^4/n, \cdots, \lfloor \frac{-\log(q_{i,z})}{\varepsilon^4 / n}\rfloor\varepsilon^4/n)$$
        \item Signature for set $S$:
            $$\mathsf{Sig}(S) = \sum_{i\in S} \mathsf{Sig}(\bar X_i).$$ 
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Signatures}
\begin{block}{Fact}
                \begin{itemize}
                    \item $\max_{i\in S} \bar X_i$ takes value on $\mathsf{Supp}$, and can be Bernoulli decomposed to $\{BD_{S,j}\}_{j=1}^z$.\\ 
                    \item $BD_{S,j} = \max_{i\in S} Y_{i,j}$, and $\Pr[BD_{S,j} = 0] = \prod_{i\in S} \Pr[Y_{i,j} = 0]$.
                \end{itemize}
            \end{block}
    \begin{lemma}
        If two sets have the same signature, their objective values differ at most $O(\varepsilon) W$.
    \end{lemma}
    \begin{spacing}{1.2}
    \onslide<2->{
    For two sets $S_1$ and $S_2$, ${\color{red} \mathsf{Sig}(S_1)} = {\color{red}\mathsf{Sig}(S_2).}$\\}
    \onslide<3->{$\Rightarrow$ ${\color{red}\sum_{S_1} \mathsf{Sig}(X_i)} = {\color{red}\sum_{S_2} \mathsf{Sig}(X_i)}$.\\}
    \onslide<4->{$\Rightarrow$ {\color{red}$\sum_{S_1} \log(q_{i,j})$} is close to {\color{red} $\sum_{S_2} \log(q_{i,j})$} for any $j$.\\}
    \onslide<5->{$\Rightarrow$ {\color{red}$\prod_{S_1} q_{i,j}$} is close to {\color{red}$\prod_{S_2}q_{i,j}$} for any $j$.\\}
    \onslide<6->{$\Rightarrow$ {\color{red}$BD_{S_1,j}$} is close to {\color{red}$BD_{S_2, j}$} for any $j$.\\}
    \onslide<7->{$\Rightarrow$ {\color{red}$\Exp[\max_{S_1} \bar X_i]$} is close to {\color{red}$\Exp[\max_{S_2} \bar X_i]$}.\\}
\end{spacing}
\end{frame}

\begin{frame}
    \newcommand{\epsw}{{\color{red} $O(\varepsilon)W$}}
    \frametitle{PTAS: Enumeration}
    \begin{enumerate}
        \onslide<1->{
        \item Discretize input random variables. \onslide<6->{{\color{red}$O(\varepsilon)W$}}
        \item Compute signatures of variables.
        }
    \onslide<2->{\item Enumerate possible signatures of sets.\onslide<7->{{\color{red}$O(\varepsilon)W$}}}
    \onslide<3->{\item For each signature, try to find a candidate with such signature.\onslide<8->{{\color{red} $O(\varepsilon)W$}}}
            \only<4-4>{ {\color{blue} Coordinates of signatures are integer multiple of $\varepsilon^4/n$.\\ 
            Encode one signature to one integer.\\
    Reduce finding a corresponding solution to \ES.\\}}
\onslide<5->{        \item Return a candidate with the best objective value as solution.}
    \onslide<9->{
        \begin{spacing}{2.0}

        \end{spacing}
    $$|SOL - OPT| \leq O(\varepsilon)W \leq O(\varepsilon)OPT$$}
    \end{enumerate}
\end{frame}

\section{MINIMUM-ELEMENT}
\begin{frame}
    \begin{problem}[\mm]
        \begin{itemize}
            \item Input: A set of independent non-negative random variables $\{X_i\}$ with cost $\{c_i\}$, a budget $C$;
            \item Output: A set $S$ with total cost at most $C$ which minimizes $\Exp[\min_{i\in S} X_i]$.
        \end{itemize}
    \end{problem}
    \begin{spacing}{2.0}

    \end{spacing}
    Alternate: Achieve $(1+\varepsilon)$-approximation with minimum cost.
\end{frame}

\begin{frame}
    \frametitle{Key Fact}
    \begin{theorem}[\cite{Goel:probe}]
        Define $f(S) =\Exp[ \min_{i\in S} X_i]$, $-\log f$ is submodular.
    \end{theorem}
    \begin{theorem}[\cite{nemhauser1978analysis}]
        \label{thm:add-submod}
Given a submodular function $g$ and budget $C$. Let $S^*$ be the optimal solution. With an initial set $S$, the greedy algorithm using extra cost at most $C\log\frac{g(S^*) - g(S)}{\varepsilon}$ finds a set $T$ such that $g(S^*) - g(T) \leq \varepsilon$.
    \end{theorem}
    \begin{spacing}{2.0}

    \end{spacing}
    $$R_1 OPT, R_2 C \Longrightarrow (1+\varepsilon)OPT, O(R_2 + \log R_1) C$$.
\end{frame}

\begin{frame}
\frametitle{Our Contributions}
\begin{theorem}
    In the case that all random variables taking value over $\{0, 1, \ldots, m - 1\}$, there is an approximation algorithm providing a $(1+\varepsilon)$-approximation with extra cost at most $O(\log\log\log m)C$.\\
    {\color{blue} Previous: extra cost $O(\log\log m)C$.}
\end{theorem}
\end{frame}

\begin{frame}
    \frametitle{CIP Approach}
    \begin{itemize}
        \item $\Exp[\min_{i\in S} X_i]
            = \sum_{j > 0} \Pr[\min_{i\in S} X_i \geq j] 
            = \sum_{j > 0} \prod_{i\in S}\Pr[X_i \geq j]$
        \item If for any $j$, $\prod_{i\in S}\Pr[X_i \geq j] \leq b_j$, then $\Exp[\min_{i\in S} X_i] \leq \sum_j b_j$.
        \item Let $u_{i,j} = -\log \Pr[X_i \geq j]$, $x_i$ represents the choice,
            \begin{align*}
                \text{minimize} & \sum c_i x_i & \\
                \text{s.t.}
                & \sum_i u_{i,j} x_i \geq -\log b_j
                & \only<1-2>{ \text{for } j = 1, 2, 3, \ldots, m - 1} 
                \only<3->{\text{for } {\color{red} j = 1, 2, 4, 8, \ldots, 2^{[\log m]}}}\\
            & x_i \in 
                \only<1-1>{\{0, 1\}} 
                \only<2->{{\color{blue} [0,1]}} 
                & \text{for } i = 1, 2, \ldots, n.
            \end{align*}
    \end{itemize}
    \only<2>{$R_1 = m, R_2 = O(\log m)$}
    \only<3>{$R_1 = O(\log m), R_2 = O(\log\log m)$}
\end{frame}

\begin{frame}
    \frametitle{Our Improvement}
     \begin{align*}
                \text{minimize} & \sum c_i x_i & \\
                \text{s.t.}
                & \sum_i u_{i,j} x_i \geq z_j
                & \text{for } j = 1, \ldots, N\\
            & x_i \in \{0, 1\}
                & \text{for } i = 1, \ldots, n.
            \end{align*}

        \begin{theorem}
            If $\{u_{i,j}\}$ is column monotone, $\max z_j \leq T\min z_j$, we can find an integer solution with probability at least $1-2\delta$ in polynomial time such that
            $$\sum c_ix_i \leq O(\log\log T)OPT,$$
            and
            $$\sum_i u_{i,j} x_i \geq z_j - 1.$$
        \end{theorem}
\end{frame}

\begin{frame}
    \frametitle{Our Improvement}
    \begin{itemize}
        \item Assume $b_j$ powers of $2$, $\{-\log b_j\}$ is a monotone integer vector;
        \item If the objective value is $W$, $-\log b_j$ can be bounded in $[\log\frac{1}{W}, \log\frac{m}{\varepsilon W}]$;
        \item Guess optimal value $W$ and enumerate possible $\{b_j\}$. Solve the CIP.
        \item $R_1 = O(1), R_2 = O(\log\log\log m)$;
    \end{itemize}

\end{frame}

\section{Future Work}
\begin{frame}
    \frametitle{Future Work}
    \begin{itemize}
        \item Adaptive result for both \MM\ and \mm?
        \item FPTAS for \MM?
        \item Constant approximation or even PTAS on the cost of \mm?
        \item What if taking the $K$-th largest element as objective instead of the largest?
    \end{itemize}
\end{frame}

\begin{frame}
Questions?
\end{frame}

\begin{frame}\frametitle{Reference}
\bibliographystyle{plain}
\bibliography{proposal}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
